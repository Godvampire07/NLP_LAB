{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243,
     "referenced_widgets": [
      "e9d7686493d34681b3199fa0d3342af0",
      "52e9f0e714ba4d059271d1d41ea5cc9a",
      "d06d181633b9464c8f02ebc98c904b4c",
      "b52066e5d7a749168fb1c8f54fb4bd4e",
      "a4309b08240942eb995d47fc34d07a4a",
      "dd895310c7b94189b224bb786b3b49db",
      "385ea8f7ccee4ee2aa531a7f59864cf8",
      "03ae07515bfd4e0391c7a505ab937503",
      "a4078f55069f4eeaa3eed9b69dceff2c",
      "5246e18a5793401cbdea272feb5d9898",
      "7a5e35be74e142378e64bb1e41a51638"
     ]
    },
    "id": "qoROEq9nZTN4",
    "outputId": "f06fad6a-dc3d-4450-968a-e3bbb6ce41fb"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ai4bharat/IndicCorpV2\",split = \"mar_Deva\" , streaming = True)\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4pPywaweCndi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AuGti1uvfl30",
    "outputId": "a78ae107-20d4-4e40-d46c-217e439f3e3f"
   },
   "outputs": [],
   "source": [
    "#sample values\n",
    "for i, example in enumerate(islice(dataset, 5)):\n",
    "    print(f\"{example['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QqMrcnDkR6iO"
   },
   "outputs": [],
   "source": [
    "# Sentence tokenizer\n",
    "def sentence_tokenizer(text):\n",
    "    return re.split(r'(?<=[\u0964!?|])\\s+', text.strip())\n",
    "\n",
    "# Word tokenizer\n",
    "def word_tokenizer(sentence):\n",
    "    pattern = r'''(?x)\n",
    "        (https?://[^\\s]+)                    # URLs\n",
    "      | (\\w+@\\w+\\.\\w+)                       # Emails\n",
    "      | (\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4})      # Dates\n",
    "      | (\\d+\\.\\d+)                           # Decimals\n",
    "      | (\\d+)                                # Whole numbers\n",
    "      | ([\\u0900-\\u097F]+)                   # Devanagari (Marathi/Hindi) words\n",
    "      | ([a-zA-Z]+)                          # English words\n",
    "      | ([\u0964.,!?;:\"'\\-\u2014()])                   # Punctuation\n",
    "    '''\n",
    "    tokens = re.findall(pattern, sentence)\n",
    "    # Flatten the list of tuples into a single list\n",
    "    return [t for group in tokens for t in group if t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I706E1_hU821"
   },
   "outputs": [],
   "source": [
    "# this is not used (only for understanding)\n",
    "# Word tokenizer\n",
    "#def word_tokenizer(sentence):\n",
    "    pattern = r'''(?x)\n",
    "        (?:https?://[^\\s]+)                   # URLs\n",
    "        | (?:\\w+@\\w+\\.\\w+)                    # Emails\n",
    "        | (?:\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4})   # Dates\n",
    "        | (?:\\d+\\.\\d+)                        # Decimals\n",
    "        | (?:\\d+)                             # Whole numbers\n",
    "        | (?:\\w+|[^\\w\\s])                     # Words and punctuation\n",
    "    '''\n",
    "    return re.findall(pattern, sentence)\n",
    "# does not properly tokenize Marathi words (Devanagari script) unless you use Unicode-aware regex.\n",
    "#Python's \\w does not include Devanagari characters by default.\n",
    "# This is incorrect, as it's splitting valid Marathi words into letters and matras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-YeioX6sSfws",
    "outputId": "97338d8d-d55d-4642-b05a-dc31edebde8f"
   },
   "outputs": [],
   "source": [
    "sentence = sentence_tokenizer('\u092e\u091c\u0915\u0941\u0930\u093e\u091a\u093e \u092a\u0948\u0932\u0942  \u092e\u093e\u0917\u0940\u0932 \u0915\u0945\u092e\u0947\u0930\u093e ?, \u0921\u094d\u092f\u0941\u0905\u0932 \u091f\u094b\u0928!! \u090f\u0932. \u0908. \u0921\u0940. \u092b\u094d\u0932\u0945\u0936 \u0906\u0923\u093f \u092b\u093f\u0902\u0917\u0930\u092a\u094d\u0930\u093f\u0902\u091f \u0938\u094d\u0915\u0945\u0928\u0930\u091a\u0940 \u0938\u0947\u091f\u0905\u092a \u0935\u0948\u0936\u093f\u0937\u094d\u091f\u094d\u092f\u0947 \u0930\u0947\u0921\u092e\u0940 \u0928\u094b\u091f 3 \u0938\u093e\u0930\u0916\u0940\u091a \u0906\u0939\u0947\u0924|')\n",
    "print(sentence)\n",
    "#Split the text wherever there is a space following a sentence-ending punctuation mark (\u0964, !, ?, or |)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jaVXQSdBTe0_",
    "outputId": "dce259fd-2081-4e82-dc0f-2d1aa5d46d5c"
   },
   "outputs": [],
   "source": [
    "#using the unicode- aware tokenizer\n",
    "words = word_tokenizer(sentence[-1])\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95qxNWqUEMgA",
    "outputId": "60596de2-bb38-4dc1-b5e3-3ee955eaab65"
   },
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "max_examples = 5000  # Or any other limit\n",
    "tokenized_sentences = []\n",
    "total_words = 0\n",
    "total_chars = 0\n",
    "unique_tokens = set()\n",
    "\n",
    "# Safely iterate over streaming dataset with limit\n",
    "for example in islice(dataset, max_examples):\n",
    "    text = example[\"text\"]\n",
    "    sentences = sentence_tokenizer(text)\n",
    "    for sentence in sentences:\n",
    "        tokens = word_tokenizer(sentence)\n",
    "        if tokens:\n",
    "            tokenized_sentence = \" \".join(tokens)\n",
    "            tokenized_sentences.append(tokenized_sentence)\n",
    "            total_words += len(tokens)\n",
    "            total_chars += sum(len(t) for t in tokens)\n",
    "            unique_tokens.update(tokens)\n",
    "\n",
    "# Step 4: Save to file\n",
    "df = pd.DataFrame({'sentence': tokenized_sentences})\n",
    "df.to_csv(\"marathi_tokenized_sentences.csv\", index=False, encoding=\"utf-8\")\n",
    "# Corpus statistics\n",
    "num_sentences = len(tokenized_sentences)\n",
    "avg_sentence_length = total_words / num_sentences\n",
    "avg_word_length = total_chars / total_words\n",
    "ttr = len(unique_tokens) / total_words\n",
    "token_count = len(unique_tokens)\n",
    "print(\"Corpus Statistics:\")\n",
    "print(f\"Total number of sentences: {num_sentences}\")\n",
    "print(f\"Total number of words: {total_words}\")\n",
    "print(f\"Unique_tokens:{token_count}\")\n",
    "print(f\"Total number of characters: {total_chars}\")\n",
    "print(f\"Average sentence length: {avg_sentence_length:.2f}\")\n",
    "print(f\"Average word length: {avg_word_length:.2f}\")\n",
    "print(f\"Type/Token Ratio (TTR): {ttr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "byscI0gXDORo",
    "outputId": "4cde074a-28a7-4151-a19a-94b3bc4712ac"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "I7HlppCDLtSU",
    "outputId": "65caf6f5-309a-4c2a-ba59-34b56712aa59"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"marathi_tokenized_sentences.csv\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngU52T1AhIcr"
   },
   "source": [
    " \u2705 For CSV files opened in Excel:\n",
    "When opening in Excel:\n",
    "\n",
    "Don't double-click to open!\n",
    "\n",
    "Instead:\n",
    "\n",
    "Open Excel.\n",
    "\n",
    "Go to File > Open > Browse.\n",
    "\n",
    "In the Open dialog, select \"All Files\" and choose your CSV.\n",
    "\n",
    "You'll get a Text Import Wizard:\n",
    "\n",
    "Select \"65001: Unicode (UTF-8)\" as the encoding.\n",
    "\n",
    "Use comma (,) as delimiter.\n",
    "\n",
    "Finish.\n",
    "\n",
    "This will render Marathi text correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAHpVz8ChY2d"
   },
   "outputs": [],
   "source": [
    "#!pip install pyarrow\n",
    "# Assuming df is your DataFrame with tokenized sentences\n",
    "df.to_parquet(\"marathi_tokenized_sentences.parquet\", engine='pyarrow', compression='snappy', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "collapsed": true,
    "id": "wakaVOIQZ0Pp",
    "outputId": "ce0a495a-acb4-4985-f79b-e3800453fc7b"
   },
   "outputs": [],
   "source": [
    "word_lengths = [len(word) for sentence in tokenized_sentences for word in sentence.split()]\n",
    "sentence_lengths = [len(sentence.split()) for sentence in tokenized_sentences]\n",
    "all_words = [word for sentence in tokenized_sentences for word in sentence.split()]\n",
    "word_freq = Counter(all_words).most_common(20)\n",
    "# Plot 1: Word Length Distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(word_lengths, bins=range(1, max(word_lengths) + 1), kde=False)\n",
    "plt.title(\"Distribution of Word Lengths\")\n",
    "plt.xlabel(\"Word Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "-LoKdMaxbEev",
    "outputId": "09378cc9-7d8a-4745-9ce2-debe382392f9"
   },
   "outputs": [],
   "source": [
    "# Plot 2: Sentence Length Distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(sentence_lengths, bins=range(1, max(sentence_lengths) + 1), kde=False)\n",
    "plt.title(\"Distribution of Sentence Lengths\")\n",
    "plt.xlabel(\"Number of Words per Sentence\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iAKIvZ9ubPWL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}